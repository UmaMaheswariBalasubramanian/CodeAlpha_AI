{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1067156,"sourceType":"datasetVersion","datasetId":592212}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:22:14.731340Z","iopub.execute_input":"2025-01-06T07:22:14.731588Z","iopub.status.idle":"2025-01-06T07:22:14.741505Z","shell.execute_reply.started":"2025-01-06T07:22:14.731555Z","shell.execute_reply":"2025-01-06T07:22:14.740664Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/language-translation-englishfrench/eng_-french.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **Important Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport re\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Bidirectional, Concatenate, Layer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:22:14.742617Z","iopub.execute_input":"2025-01-06T07:22:14.742922Z","iopub.status.idle":"2025-01-06T07:22:22.919811Z","shell.execute_reply.started":"2025-01-06T07:22:14.742893Z","shell.execute_reply":"2025-01-06T07:22:22.919116Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# **Load Dataset**","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/language-translation-englishfrench/eng_-french.csv', names=[\"English\", \"French\"], header=0)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:22:22.923587Z","iopub.execute_input":"2025-01-06T07:22:22.923778Z","iopub.status.idle":"2025-01-06T07:22:23.402630Z","shell.execute_reply.started":"2025-01-06T07:22:22.923760Z","shell.execute_reply":"2025-01-06T07:22:23.401861Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"  English      French\n0     Hi.      Salut!\n1    Run!     Cours !\n2    Run!    Courez !\n3    Who?       Qui ?\n4    Wow!  Ça alors !","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Salut!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Who?</td>\n      <td>Qui ?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# **Data Cleaning and Spliting**","metadata":{}},{"cell_type":"code","source":"# Clean English text\ndef clean_english_text(text):\n    text = text.lower()\n    contractions = {\n        \"i'm\": \"i am\", \"you're\": \"you are\", \"it's\": \"it is\",\n        \"can't\": \"cannot\", \"don't\": \"do not\", \"didn't\": \"did not\",\n        \"i've\": \"i have\", \"we're\": \"we are\", \"isn't\": \"is not\",\n        \"won't\": \"will not\", \"aren't\": \"are not\"\n    }\n    for contraction, full_form in contractions.items():\n        text = re.sub(r'\\b{}\\b'.format(contraction), full_form, text)\n    text = re.sub(r\"[^a-z\\s]+\", \"\", text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\n# Clean French text\ndef clean_french_text(text):\n    text = text.lower()\n    contractions = {\n        \"c'est\": \"ce est\", \"j'ai\": \"je ai\", \"il y a\": \"il y avoir\",\n        \"n'est\": \"ne est\", \"qu'est\": \"que est\", \"d'accord\": \"de accord\"\n    }\n    for contraction, full_form in contractions.items():\n        text = re.sub(r'\\b{}\\b'.format(contraction), full_form, text)\n    text = re.sub(r\"[^a-z\\u00e0\\u00e8\\u00e9\\u00e2\\u00ea\\u00ee\\u00f4\\u00fb\\u00e7\\u00f9\\u00ef\\u00fc\\u0153\\s]+\", \"\", text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:22:28.806579Z","iopub.execute_input":"2025-01-06T07:22:28.806887Z","iopub.status.idle":"2025-01-06T07:22:28.812975Z","shell.execute_reply.started":"2025-01-06T07:22:28.806864Z","shell.execute_reply":"2025-01-06T07:22:28.812001Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Apply text cleaning\ndf[\"English\"] = df[\"English\"].apply(clean_english_text)\ndf[\"French\"] = df[\"French\"].apply(clean_french_text)\n\n# Add special tokens for French sequences\ndf[\"French\"] = df[\"French\"].apply(lambda x: f\"<start> {x} <end>\")\n\n# Extract cleaned sentences\nenglish_sentences = df[\"English\"].tolist()\nfrench_sentences = df[\"French\"].tolist()\nprint(\"Cleaned English Sentences:\", english_sentences[:5])\nprint(\"Cleaned French Sentences:\", french_sentences[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:22:31.756918Z","iopub.execute_input":"2025-01-06T07:22:31.757277Z","iopub.status.idle":"2025-01-06T07:22:38.675996Z","shell.execute_reply.started":"2025-01-06T07:22:31.757246Z","shell.execute_reply":"2025-01-06T07:22:38.675236Z"}},"outputs":[{"name":"stdout","text":"Cleaned English Sentences: ['hi', 'run', 'run', 'who', 'wow']\nCleaned French Sentences: ['<start> salut <end>', '<start> cours <end>', '<start> courez <end>', '<start> qui <end>', '<start> ça alors <end>']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Split data\ntrain_english, test_english, train_french, test_french = train_test_split(\n    df[\"English\"], df[\"French\"], test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:22:42.690328Z","iopub.execute_input":"2025-01-06T07:22:42.691133Z","iopub.status.idle":"2025-01-06T07:22:42.737876Z","shell.execute_reply.started":"2025-01-06T07:22:42.691089Z","shell.execute_reply":"2025-01-06T07:22:42.736665Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# **Tokenization**","metadata":{}},{"cell_type":"code","source":"# Preprocessing function\ndef preprocess_text(tokenizer, texts, max_len):\n    sequences = tokenizer.texts_to_sequences(texts)\n    return pad_sequences(sequences, maxlen=max_len, padding='post')\n\n# Tokenization and Padding\nmax_vocab_size = 10000\nmax_sequence_length = 50\n\nenglish_tokenizer = Tokenizer(num_words=max_vocab_size)\nenglish_tokenizer.fit_on_texts(train_english)\n\nfrench_tokenizer = Tokenizer(num_words=max_vocab_size)\nfrench_tokenizer.fit_on_texts(train_french)\n\ntrain_english_padded = preprocess_text(english_tokenizer, train_english,max_sequence_length)\ntrain_french_padded = preprocess_text(french_tokenizer, train_french,max_sequence_length)\ntest_english_padded = preprocess_text(english_tokenizer, test_english,max_sequence_length)\ntest_french_padded = preprocess_text(french_tokenizer, test_french,max_sequence_length)\n\n# Prepare decoder target sequences\ntrain_decoder_target_data = train_french_padded[:, 1:]\ntrain_decoder_target_data = pad_sequences(train_decoder_target_data, maxlen=max_sequence_length, padding='post')\n\n# Vocabulary sizes\nenglish_vocab_size = len(english_tokenizer.word_index) + 1\nfrench_vocab_size = len(french_tokenizer.word_index) + 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:22:47.228785Z","iopub.execute_input":"2025-01-06T07:22:47.229118Z","iopub.status.idle":"2025-01-06T07:22:55.479614Z","shell.execute_reply.started":"2025-01-06T07:22:47.229091Z","shell.execute_reply":"2025-01-06T07:22:55.478899Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# **Model**","metadata":{}},{"cell_type":"code","source":"# Custom Attention Layer\nclass AttentionLayer(Layer):\n    def call(self, inputs):\n        decoder_outputs, encoder_outputs = inputs\n        attention_scores = tf.matmul(decoder_outputs, encoder_outputs, transpose_b=True)\n        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n        context_vector = tf.matmul(attention_weights, encoder_outputs)\n        return context_vector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:23:00.153122Z","iopub.execute_input":"2025-01-06T07:23:00.153414Z","iopub.status.idle":"2025-01-06T07:23:00.157747Z","shell.execute_reply.started":"2025-01-06T07:23:00.153395Z","shell.execute_reply":"2025-01-06T07:23:00.156941Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Seq2Seq Model with Bidirectional LSTM and Attention Mechanism\nencoder_inputs = Input(shape=(None,))\nencoder_embedding = Embedding(input_dim=english_vocab_size, output_dim=256, mask_zero=True)(encoder_inputs)\nencoder_lstm = Bidirectional(LSTM(256, return_sequences=True, return_state=True))\nencoder_outputs, forward_h, forward_c, backward_h, backward_c = encoder_lstm(encoder_embedding)\nstate_h = Concatenate()([forward_h, backward_h])\nstate_c = Concatenate()([forward_c, backward_c])\nencoder_states = [state_h, state_c]\n\ndecoder_inputs = Input(shape=(None,))\ndecoder_embedding = Embedding(input_dim=french_vocab_size, output_dim=256, mask_zero=True)(decoder_inputs)\ndecoder_lstm = LSTM(512, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n\nattention_layer = AttentionLayer()\nattention_result = attention_layer([decoder_outputs, encoder_outputs])\ndecoder_concat_input = Concatenate(axis=-1)([decoder_outputs, attention_result])\n\ndecoder_dense = Dense(french_vocab_size, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_concat_input)\n\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:23:06.482818Z","iopub.execute_input":"2025-01-06T07:23:06.483151Z","iopub.status.idle":"2025-01-06T07:23:07.896813Z","shell.execute_reply.started":"2025-01-06T07:23:06.483126Z","shell.execute_reply":"2025-01-06T07:23:07.895963Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'attention_layer' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m3,432,448\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),    │      \u001b[38;5;34m1,050,624\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │                │                        │\n│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]           │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │      \u001b[38;5;34m6,824,704\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],   │\n│                           │                        │                │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m3\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m],   │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m4\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),    │      \u001b[38;5;34m1,574,912\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │ \u001b[38;5;34m512\u001b[0m)]                  │                │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_layer           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mAttentionLayer\u001b[0m)          │                        │                │ bidirectional[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ attention_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26659\u001b[0m)    │     \u001b[38;5;34m27,325,475\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,432,448</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ bidirectional             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │                │                        │\n│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]           │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,824,704</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],   │\n│                           │                        │                │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>],   │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]                  │                │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ attention_layer           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)          │                        │                │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ attention_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26659</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">27,325,475</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,208,163\u001b[0m (153.38 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,208,163</span> (153.38 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,208,163\u001b[0m (153.38 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,208,163</span> (153.38 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Train the model with EarlyStopping callbacks\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n\nmodel.fit(\n    [train_english_padded, train_french_padded],\n    np.expand_dims(train_decoder_target_data, -1),\n    batch_size=64,\n    epochs=5,\n    validation_split=0.2,\n    callbacks=[early_stopping_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T07:23:12.890186Z","iopub.execute_input":"2025-01-06T07:23:12.890494Z","iopub.status.idle":"2025-01-06T08:00:15.483761Z","shell.execute_reply.started":"2025-01-06T07:23:12.890473Z","shell.execute_reply":"2025-01-06T08:00:15.482996Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 253ms/step - accuracy: 0.8846 - loss: 1.0170 - val_accuracy: 0.9367 - val_loss: 0.3475\nEpoch 2/5\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 252ms/step - accuracy: 0.9439 - loss: 0.2863 - val_accuracy: 0.9510 - val_loss: 0.2413\nEpoch 3/5\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 252ms/step - accuracy: 0.9588 - loss: 0.1798 - val_accuracy: 0.9557 - val_loss: 0.2093\nEpoch 4/5\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 252ms/step - accuracy: 0.9668 - loss: 0.1324 - val_accuracy: 0.9577 - val_loss: 0.1990\nEpoch 5/5\n\u001b[1m1757/1757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 252ms/step - accuracy: 0.9722 - loss: 0.1047 - val_accuracy: 0.9588 - val_loss: 0.1966\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7ca3199b20b0>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"# **Evaluate and Prediciton**","metadata":{}},{"cell_type":"code","source":"# Evaluate the model\ntest_decoder_target_data = test_french_padded[:, 1:]\ntest_decoder_target_data = pad_sequences(test_decoder_target_data, maxlen=max_sequence_length, padding='post')\nloss, accuracy = model.evaluate(\n    [test_english_padded, test_french_padded],\n    np.expand_dims(test_decoder_target_data, -1)\n)\nprint(f\"Test Loss: {loss:.2f}, Test Accuracy: {accuracy:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:00:23.114448Z","iopub.execute_input":"2025-01-06T08:00:23.114743Z","iopub.status.idle":"2025-01-06T08:01:53.039545Z","shell.execute_reply.started":"2025-01-06T08:00:23.114722Z","shell.execute_reply":"2025-01-06T08:01:53.038817Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1098/1098\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 82ms/step - accuracy: 0.9588 - loss: 0.1943\nTest Loss: 0.20, Test Accuracy: 0.96\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Inference models with Attention Mechanism\nencoder_model = Model(encoder_inputs, [encoder_outputs] + encoder_states)\n\ndecoder_state_input_h = Input(shape=(512,))\ndecoder_state_input_c = Input(shape=(512,))\ndecoder_hidden_states_input = Input(shape=(max_sequence_length, 512))\n\ndecoder_lstm_outputs, state_h_decoded, state_c_decoded = decoder_lstm(\n    decoder_embedding,\n    initial_state=[decoder_state_input_h, decoder_state_input_c]\n)\nattention_result_decoded = attention_layer([decoder_lstm_outputs, decoder_hidden_states_input])\ndecoder_concat_input_decoded = Concatenate(axis=-1)([decoder_lstm_outputs, attention_result_decoded])\ndecoder_outputs_decoded = decoder_dense(decoder_concat_input_decoded)\n\ndecoder_model = Model(\n    [decoder_inputs] + [decoder_state_input_h, decoder_state_input_c, decoder_hidden_states_input],\n    [decoder_outputs_decoded] + [state_h_decoded, state_c_decoded]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:10:21.115012Z","iopub.execute_input":"2025-01-06T08:10:21.115389Z","iopub.status.idle":"2025-01-06T08:10:21.135829Z","shell.execute_reply.started":"2025-01-06T08:10:21.115362Z","shell.execute_reply":"2025-01-06T08:10:21.134929Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'attention_layer' (of type AttentionLayer) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Reverse lookup for French vocabulary\nreverse_french_vocab = {i: word for word, i in french_tokenizer.word_index.items()}\n\ndef decode_sequence(input_seq):\n    encoder_outputs, state_h, state_c = encoder_model.predict(input_seq, verbose=0)  \n    states_value = [state_h, state_c]\n    target_seq = np.zeros((1, 1))\n    target_seq[0, 0] = french_tokenizer.word_index.get('<start>', 0)\n\n    decoded_sentence = ''\n    for _ in range(max_sequence_length): \n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value + [encoder_outputs],verbose=0)\n        \n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_word = reverse_french_vocab.get(sampled_token_index, '')\n\n        if sampled_word == '<end>':\n            break\n\n        # Append the word to the sentence\n        decoded_sentence += ' ' + sampled_word\n        target_seq[0, 0] = sampled_token_index\n        states_value = [h, c]\n\n    return decoded_sentence.replace('end','').strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:10:22.875753Z","iopub.execute_input":"2025-01-06T08:10:22.876063Z","iopub.status.idle":"2025-01-06T08:10:22.887449Z","shell.execute_reply.started":"2025-01-06T08:10:22.876016Z","shell.execute_reply":"2025-01-06T08:10:22.886589Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Create a list to store the actual and predicted translations\ntranslations = []\n\n# Generate 15 random indices within the range of the test dataset\nrandom_indices = random.sample(range(len(test_english_padded)), 10)\n\n# Test translations for randomly selected indices\nfor i in random_indices:\n    input_seq = test_english_padded[i:i + 1]\n    translated_sentence = decode_sequence(input_seq)\n    actual_sentence = test_french.iloc[i]\n    \n    # Append both actual and predicted sentences to the list\n    translations.append({\"Actual\": actual_sentence, \"Predicted\": translated_sentence})\n\n# Convert the list to a DataFrame\ntranslations_df = pd.DataFrame(translations)\n\n# Print the DataFrame with actual and predicted translations\ntranslations_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:10:25.328271Z","iopub.execute_input":"2025-01-06T08:10:25.328561Z","iopub.status.idle":"2025-01-06T08:10:59.504087Z","shell.execute_reply.started":"2025-01-06T08:10:25.328540Z","shell.execute_reply":"2025-01-06T08:10:59.503376Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                              Actual  \\\n0  <start> si tu étais ma femme je me pendrais <end>   \n1              <start> tom est très méticuleux <end>   \n2       <start> je nai pas le cran de dire non <end>   \n3  <start> je ne pense pas que je méritais la pun...   \n4  <start> je veux massurer que tu es celui que t...   \n5                      <start> asseyezvous tom <end>   \n6     <start> il a quitté le japon pour de bon <end>   \n7  <start> je suis lente à madapter à de nouvelle...   \n8                    <start> y atil un parking <end>   \n9  <start> la police commença à enquêter sur laff...   \n\n                                    Predicted  \n0                      si vous étiez ma femme  \n1                                tom est très  \n2           je nai pas les tripes de dire non  \n3            je ne pense pas que je ai obtenu  \n4       je veux massurer que vous êtes celles  \n5                              assiedstoi tom  \n6                        il a quitté le japon  \n7                    pour me faire de nouveau  \n8                           y atil un parking  \n9  la police a commencé à examiner le meurtre  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;start&gt; si tu étais ma femme je me pendrais &lt;end&gt;</td>\n      <td>si vous étiez ma femme</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;start&gt; tom est très méticuleux &lt;end&gt;</td>\n      <td>tom est très</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;start&gt; je nai pas le cran de dire non &lt;end&gt;</td>\n      <td>je nai pas les tripes de dire non</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;start&gt; je ne pense pas que je méritais la pun...</td>\n      <td>je ne pense pas que je ai obtenu</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;start&gt; je veux massurer que tu es celui que t...</td>\n      <td>je veux massurer que vous êtes celles</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;start&gt; asseyezvous tom &lt;end&gt;</td>\n      <td>assiedstoi tom</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>&lt;start&gt; il a quitté le japon pour de bon &lt;end&gt;</td>\n      <td>il a quitté le japon</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>&lt;start&gt; je suis lente à madapter à de nouvelle...</td>\n      <td>pour me faire de nouveau</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>&lt;start&gt; y atil un parking &lt;end&gt;</td>\n      <td>y atil un parking</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>&lt;start&gt; la police commença à enquêter sur laff...</td>\n      <td>la police a commencé à examiner le meurtre</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}